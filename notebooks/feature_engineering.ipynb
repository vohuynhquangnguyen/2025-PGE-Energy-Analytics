{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47841992",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc74bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b36d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load training data (Years 1 and 2) ---\n",
    "train_df = pd.read_excel('.././datasets/training.xlsx', sheet_name='Data')\n",
    "\n",
    "# --- Load testing data (Year 3)\n",
    "test_df = pd.read_excel('.././datasets/testing.xlsx', sheet_name='Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f84a0",
   "metadata": {},
   "source": [
    "## Dimensional Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2287c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Performing PLS Dimensionality Reduction...\n",
      "PLS transformation complete. 'Combined_Temp' and 'Combined_GHI' created.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 0: Prepare the Data ---\n",
    "# For consistency, we'll combine the training and testing sets to apply features.\n",
    "# We'll fit the PLS model ONLY on the training data to prevent data leakage.\n",
    "train_rows = len(train_df)\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# --- Step 1: PLS Dimensionality Reduction ---\n",
    "print(\"Step 1: Performing PLS Dimensionality Reduction...\")\n",
    "\n",
    "# Define predictor sets and the target variable ('Load')\n",
    "temp_cols = sorted([col for col in full_df.columns if 'Temp' in col])\n",
    "ghi_cols = sorted([col for col in full_df.columns if 'GHI' in col])\n",
    "target_col = 'Load'\n",
    "\n",
    "# Isolate the training data to fit the models\n",
    "X_train_temp = train_df[temp_cols]\n",
    "X_train_ghi = train_df[ghi_cols]\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "# a) PLS for Temperature\n",
    "pls_temp = PLSRegression(n_components=1)\n",
    "pls_temp.fit(X_train_temp, y_train)\n",
    "full_df['Combined_Temp'] = pls_temp.transform(full_df[temp_cols])\n",
    "\n",
    "# b) PLS for GHI\n",
    "pls_ghi = PLSRegression(n_components=1)\n",
    "pls_ghi.fit(X_train_ghi, y_train)\n",
    "full_df['Combined_GHI'] = pls_ghi.transform(full_df[ghi_cols])\n",
    "\n",
    "print(\"PLS transformation complete. 'Combined_Temp' and 'Combined_GHI' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ef469",
   "metadata": {},
   "source": [
    "## New Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9fb891",
   "metadata": {},
   "source": [
    "### Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57d39f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time features created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quang\\AppData\\Local\\Temp\\ipykernel_23992\\3994866085.py:56: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  full_df['is_holiday'] = full_df['Date'].isin(us_holidays).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Create mappings for month-day calculations\n",
    "days_in_month = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30, 7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}\n",
    "cumulative_days_map = {i: sum(list(days_in_month.values())[:i-1]) for i in range(1, 13)}\n",
    "\n",
    "# Clean data and convert to integer\n",
    "full_df.dropna(subset=['Month', 'Day'], inplace=True)\n",
    "full_df['Month'] = full_df['Month'].astype(int)\n",
    "full_df['Day'] = full_df['Day'].astype(int)\n",
    "\n",
    "# Calculate DayOfYear and DayOfWeek\n",
    "max_days = full_df['Month'].map(days_in_month)\n",
    "full_df['Day_Clipped'] = np.minimum(full_df['Day'], max_days)\n",
    "cumulative_days = full_df['Month'].map(cumulative_days_map)\n",
    "full_df['DayOfYear'] = cumulative_days + full_df['Day_Clipped']\n",
    "full_df['DayOfWeek'] = (full_df['DayOfYear'] - 1) % 7\n",
    "# --- End of Fix ---\n",
    "\n",
    "\n",
    "# 1. Sinusoidal Encodings\n",
    "P_day = 24\n",
    "P_week = 168\n",
    "P_year = 8766 # 365.25 * 24\n",
    "\n",
    "# Create a continuous time index 't'\n",
    "full_df['Timestep'] = np.arange(len(full_df))\n",
    "t = full_df['Timestep']\n",
    "\n",
    "# Daily patterns (k=2)\n",
    "full_df['sin_day'] = np.sin(2 * np.pi * 2 * t / P_day)\n",
    "full_df['cos_day'] = np.cos(2 * np.pi * 2 * t / P_day)\n",
    "\n",
    "# Weekly patterns (k=2)\n",
    "full_df['sin_week'] = np.sin(2 * np.pi * 2 * t / P_week)\n",
    "full_df['cos_week'] = np.cos(2 * np.pi * 2 * t / P_week)\n",
    "\n",
    "# Yearly/Seasonal patterns (k=4)\n",
    "full_df['sin_year'] = np.sin(2 * np.pi * 4 * t / P_year)\n",
    "full_df['cos_year'] = np.cos(2 * np.pi * 4 * t / P_year)\n",
    "\n",
    "# 2. Day-of-Week Encoding\n",
    "# 'DayOfWeek' (0=Mon, 6=Sun) now exists, so we can proceed.\n",
    "# We'll rename it for clarity.\n",
    "full_df.rename(columns={'DayOfWeek': 'dow'}, inplace=True)\n",
    "\n",
    "# Weekday (0) vs. Weekend (1)\n",
    "full_df['is_weekend'] = full_df['dow'].apply(lambda d: 1 if d >= 5 else 0)\n",
    "\n",
    "# Holiday encoding (0=No, 1=Yes)\n",
    "# We map Year 1, 2, 3 to actual years to use the holiday library.\n",
    "year_map = {1: 2021, 2: 2022, 3: 2023}\n",
    "full_df['Date'] = pd.to_datetime(full_df['Year'].map(year_map).astype(str) + '-' +\n",
    "                               full_df['Month'].astype(str) + '-' +\n",
    "                               full_df['Day'].astype(str), errors='coerce')\n",
    "\n",
    "us_holidays = holidays.US(state='CA', years=[2021, 2022, 2023])\n",
    "full_df['is_holiday'] = full_df['Date'].isin(us_holidays).astype(int)\n",
    "\n",
    "print(\"Time features created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13462ee3",
   "metadata": {},
   "source": [
    "### Weather Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aada6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "# 3. Weather Lags and Deltas for Combined_Temp\n",
    "full_df['lag_1_temp'] = full_df['Combined_Temp'].shift(1)\n",
    "full_df['lag_24_temp'] = full_df['Combined_Temp'].shift(24)\n",
    "full_df['delta_1_temp'] = full_df['Combined_Temp'].diff(1)\n",
    "full_df['delta_24_temp'] = full_df['Combined_Temp'].diff(24)\n",
    "\n",
    "# Lags and Deltas for Combined_GHI\n",
    "full_df['lag_1_ghi'] = full_df['Combined_GHI'].shift(1)\n",
    "full_df['lag_24_ghi'] = full_df['Combined_GHI'].shift(24)\n",
    "full_df['delta_1_ghi'] = full_df['Combined_GHI'].diff(1)\n",
    "full_df['delta_24_ghi'] = full_df['Combined_GHI'].diff(24)\n",
    "print(\"Weather feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc8f33",
   "metadata": {},
   "source": [
    "### Behavioral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b02634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature creation complete.\n",
      "\n",
      "NaN values in lag/delta columns have been imputed with 0.\n",
      "Engineered features saved to '../datasets/features_engineered.csv'.\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26304 entries, 0 to 26303\n",
      "Data columns (total 40 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Year           26304 non-null  int64         \n",
      " 1   Month          26304 non-null  int64         \n",
      " 2   Day            26304 non-null  int64         \n",
      " 3   Hour           26304 non-null  int64         \n",
      " 4   Load           17544 non-null  float64       \n",
      " 5   Site-1 Temp    26304 non-null  float64       \n",
      " 6   Site-2 Temp    26304 non-null  float64       \n",
      " 7   Site-3 Temp    26304 non-null  float64       \n",
      " 8   Site-4 Temp    26304 non-null  float64       \n",
      " 9   Site-5 Temp    26304 non-null  float64       \n",
      " 10  Site-1 GHI     26304 non-null  int64         \n",
      " 11  Site-2 GHI     26304 non-null  int64         \n",
      " 12  Site-3 GHI     26304 non-null  int64         \n",
      " 13  Site-4 GHI     26304 non-null  int64         \n",
      " 14  Site-5 GHI     26304 non-null  int64         \n",
      " 15  Combined_Temp  26304 non-null  float64       \n",
      " 16  Combined_GHI   26304 non-null  float64       \n",
      " 17  Day_Clipped    26304 non-null  int64         \n",
      " 18  DayOfYear      26304 non-null  int64         \n",
      " 19  dow            26304 non-null  int64         \n",
      " 20  Timestep       26304 non-null  int64         \n",
      " 21  sin_day        26304 non-null  float64       \n",
      " 22  cos_day        26304 non-null  float64       \n",
      " 23  sin_week       26304 non-null  float64       \n",
      " 24  cos_week       26304 non-null  float64       \n",
      " 25  sin_year       26304 non-null  float64       \n",
      " 26  cos_year       26304 non-null  float64       \n",
      " 27  is_weekend     26304 non-null  int64         \n",
      " 28  Date           26280 non-null  datetime64[ns]\n",
      " 29  is_holiday     26304 non-null  int64         \n",
      " 30  lag_1_temp     26304 non-null  float64       \n",
      " 31  lag_24_temp    26304 non-null  float64       \n",
      " 32  delta_1_temp   26304 non-null  float64       \n",
      " 33  delta_24_temp  26304 non-null  float64       \n",
      " 34  lag_1_ghi      26304 non-null  float64       \n",
      " 35  lag_24_ghi     26304 non-null  float64       \n",
      " 36  delta_1_ghi    26304 non-null  float64       \n",
      " 37  delta_24_ghi   26304 non-null  float64       \n",
      " 38  CDH            26304 non-null  float64       \n",
      " 39  HDH            26304 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(24), int64(15)\n",
      "memory usage: 8.0 MB\n",
      "\n",
      "First 5 rows of the new features (with NaNs imputed):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Load",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Combined_Temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Combined_GHI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sin_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cos_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_weekend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_holiday",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lag_24_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_1_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CDH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HDH",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4b9591da-3aba-4e16-bf62-1fe88179faa0",
       "rows": [
        [
         "0",
         "2021-01-01 00:00:00",
         "1997.0",
         "-4.042278634795731",
         "-1.6461350356732558",
         "0.0",
         "1.0",
         "0",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "24.042278634795732"
        ],
        [
         "1",
         "2021-01-01 00:00:00",
         "1921.0",
         "-4.137674035906877",
         "-1.6461350356732558",
         "0.49999999999999994",
         "0.8660254037844387",
         "0",
         "1",
         "0.0",
         "-0.09539540111114597",
         "0.0",
         "24.137674035906876"
        ],
        [
         "2",
         "2021-01-01 00:00:00",
         "1861.0",
         "-4.205328930628448",
         "-1.6461350356732558",
         "0.8660254037844386",
         "0.5000000000000001",
         "0",
         "1",
         "0.0",
         "-0.06765489472157071",
         "0.0",
         "24.205328930628447"
        ],
        [
         "3",
         "2021-01-01 00:00:00",
         "1833.0",
         "-4.409676234179681",
         "-1.6461350356732558",
         "1.0",
         "6.123233995736766e-17",
         "0",
         "1",
         "0.0",
         "-0.20434730355123332",
         "0.0",
         "24.40967623417968"
        ],
        [
         "4",
         "2021-01-01 00:00:00",
         "1847.0",
         "-4.43578972454986",
         "-1.6461350356732558",
         "0.8660254037844387",
         "-0.4999999999999998",
         "0",
         "1",
         "0.0",
         "-0.026113490370178738",
         "0.0",
         "24.43578972454986"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Load</th>\n",
       "      <th>Combined_Temp</th>\n",
       "      <th>Combined_GHI</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>lag_24_temp</th>\n",
       "      <th>delta_1_temp</th>\n",
       "      <th>CDH</th>\n",
       "      <th>HDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>-4.042279</td>\n",
       "      <td>-1.646135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.042279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>-4.137674</td>\n",
       "      <td>-1.646135</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.137674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>-4.205329</td>\n",
       "      <td>-1.646135</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.205329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>-4.409676</td>\n",
       "      <td>-1.646135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.204347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.409676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>-4.435790</td>\n",
       "      <td>-1.646135</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.026113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.435790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Load  Combined_Temp  Combined_GHI   sin_day       cos_day  \\\n",
       "0 2021-01-01  1997.0      -4.042279     -1.646135  0.000000  1.000000e+00   \n",
       "1 2021-01-01  1921.0      -4.137674     -1.646135  0.500000  8.660254e-01   \n",
       "2 2021-01-01  1861.0      -4.205329     -1.646135  0.866025  5.000000e-01   \n",
       "3 2021-01-01  1833.0      -4.409676     -1.646135  1.000000  6.123234e-17   \n",
       "4 2021-01-01  1847.0      -4.435790     -1.646135  0.866025 -5.000000e-01   \n",
       "\n",
       "   is_weekend  is_holiday  lag_24_temp  delta_1_temp  CDH        HDH  \n",
       "0           0           1          0.0      0.000000  0.0  24.042279  \n",
       "1           0           1          0.0     -0.095395  0.0  24.137674  \n",
       "2           0           1          0.0     -0.067655  0.0  24.205329  \n",
       "3           0           1          0.0     -0.204347  0.0  24.409676  \n",
       "4           0           1          0.0     -0.026113  0.0  24.435790  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 10 original site-specific columns.\n",
      "Final feature set saved to '../datasets/features_final.csv'.\n",
      "\n",
      "Final columns in the dataset:\n",
      "['Year', 'Month', 'Day', 'Hour', 'Load', 'Combined_Temp', 'Combined_GHI', 'Day_Clipped', 'DayOfYear', 'dow', 'Timestep', 'sin_day', 'cos_day', 'sin_week', 'cos_week', 'sin_year', 'cos_year', 'is_weekend', 'Date', 'is_holiday', 'lag_1_temp', 'lag_24_temp', 'delta_1_temp', 'delta_24_temp', 'lag_1_ghi', 'lag_24_ghi', 'delta_1_ghi', 'delta_24_ghi', 'CDH', 'HDH']\n"
     ]
    }
   ],
   "source": [
    "# 4. Heating/Cooling Degree Hours\n",
    "T_base = 20.0\n",
    "full_df['CDH'] = (full_df['Combined_Temp'] - T_base).clip(lower=0)\n",
    "full_df['HDH'] = (T_base - full_df['Combined_Temp']).clip(lower=0)\n",
    "\n",
    "print(\"Feature creation complete.\")\n",
    "\n",
    "# --- Step 3: Finalize and Save ---\n",
    "lag_delta_cols = [\n",
    "    'lag_1_temp', 'lag_24_temp', 'delta_1_temp', 'delta_24_temp',\n",
    "    'lag_1_ghi', 'lag_24_ghi', 'delta_1_ghi', 'delta_24_ghi'\n",
    "]\n",
    "full_df[lag_delta_cols] = full_df[lag_delta_cols].fillna(0)\n",
    "print(\"\\nNaN values in lag/delta columns have been imputed with 0.\")\n",
    "\n",
    "final_features_df = full_df.copy()\n",
    "\n",
    "# Save the resulting dataframe to a new file\n",
    "output_filename = '../datasets/features_engineered.csv'\n",
    "final_features_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Engineered features saved to '{output_filename}'.\")\n",
    "print(\"\\nDataFrame Info:\")\n",
    "final_features_df.info()\n",
    "print(\"\\nFirst 5 rows of the new features (with NaNs imputed):\")\n",
    "# Display a subset of the new features for review\n",
    "display(final_features_df[['Date', 'Load', 'Combined_Temp', 'Combined_GHI', 'sin_day', 'cos_day', 'is_weekend', 'is_holiday', 'lag_24_temp', 'delta_1_temp', 'CDH', 'HDH']].head())\n",
    "\n",
    "# Load the dataset with all engineered features\n",
    "df = pd.read_csv(output_filename)\n",
    "\n",
    "# Find all the original site-specific columns to remove\n",
    "cols_to_drop = [col for col in df.columns if 'Site' in col and ('Temp' in col or 'GHI' in col)]\n",
    "\n",
    "# Drop the columns\n",
    "df_final = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Save the final, clean dataset\n",
    "output_filename = '../datasets/features_final.csv'\n",
    "df_final.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Removed {len(cols_to_drop)} original site-specific columns.\")\n",
    "print(f\"Final feature set saved to '{output_filename}'.\")\n",
    "\n",
    "# Display the remaining columns to confirm\n",
    "print(\"\\nFinal columns in the dataset:\")\n",
    "print(df_final.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9f877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
